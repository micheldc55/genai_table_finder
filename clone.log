2023-09-11 10:55:54,464 - ERROR - Retrying: 1...
2023-09-11 10:55:54,465 - ERROR - Exception: No API key provided. You can set your API key in code using 'openai.api_key = <API-KEY>', or you can set the environment variable OPENAI_API_KEY=<API-KEY>). If your API key is stored in a file, you can point the openai module at it with 'openai.api_key_path = <PATH>'. You can generate API keys in the OpenAI web interface. See https://platform.openai.com/account/api-keys for details.
2023-09-11 10:55:59,472 - ERROR - Retrying: 2...
2023-09-11 10:55:59,478 - ERROR - Exception: No API key provided. You can set your API key in code using 'openai.api_key = <API-KEY>', or you can set the environment variable OPENAI_API_KEY=<API-KEY>). If your API key is stored in a file, you can point the openai module at it with 'openai.api_key_path = <PATH>'. You can generate API keys in the OpenAI web interface. See https://platform.openai.com/account/api-keys for details.
2023-09-11 10:56:09,487 - ERROR - Retrying: 3...
2023-09-11 10:56:09,491 - ERROR - Exception: No API key provided. You can set your API key in code using 'openai.api_key = <API-KEY>', or you can set the environment variable OPENAI_API_KEY=<API-KEY>). If your API key is stored in a file, you can point the openai module at it with 'openai.api_key_path = <PATH>'. You can generate API keys in the OpenAI web interface. See https://platform.openai.com/account/api-keys for details.
2023-09-11 10:59:16,184 - INFO - error_code=context_length_exceeded error_message="This model's maximum context length is 4097 tokens. However, your messages resulted in 4807 tokens. Please reduce the length of the messages." error_param=messages error_type=invalid_request_error message='OpenAI API error received' stream_error=False
2023-09-11 10:59:16,193 - ERROR - Retrying: 1...
2023-09-11 10:59:16,196 - ERROR - Exception: This model's maximum context length is 4097 tokens. However, your messages resulted in 4807 tokens. Please reduce the length of the messages.
2023-09-11 10:59:21,613 - INFO - error_code=context_length_exceeded error_message="This model's maximum context length is 4097 tokens. However, your messages resulted in 4807 tokens. Please reduce the length of the messages." error_param=messages error_type=invalid_request_error message='OpenAI API error received' stream_error=False
2023-09-11 10:59:21,615 - ERROR - Retrying: 2...
2023-09-11 10:59:21,617 - ERROR - Exception: This model's maximum context length is 4097 tokens. However, your messages resulted in 4807 tokens. Please reduce the length of the messages.
2023-09-11 10:59:32,108 - INFO - error_code=context_length_exceeded error_message="This model's maximum context length is 4097 tokens. However, your messages resulted in 4807 tokens. Please reduce the length of the messages." error_param=messages error_type=invalid_request_error message='OpenAI API error received' stream_error=False
2023-09-11 10:59:32,114 - ERROR - Retrying: 3...
2023-09-11 10:59:32,116 - ERROR - Exception: This model's maximum context length is 4097 tokens. However, your messages resulted in 4807 tokens. Please reduce the length of the messages.
2023-09-11 10:59:52,431 - INFO - error_code=context_length_exceeded error_message="This model's maximum context length is 4097 tokens. However, your messages resulted in 4807 tokens. Please reduce the length of the messages." error_param=messages error_type=invalid_request_error message='OpenAI API error received' stream_error=False
2023-09-11 13:56:44,448 - ERROR - Retrying: 1...
2023-09-11 13:56:44,457 - ERROR - Exception: Request timed out: HTTPSConnectionPool(host='api.openai.com', port=443): Read timed out. (read timeout=600)
