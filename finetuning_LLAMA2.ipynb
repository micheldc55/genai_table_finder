{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Imports & Dataset Loading"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install -q accelerate==0.21.0 peft==0.4.0 bitsandbytes==0.40.2 transformers==4.31.0 trl==0.4.7 torch"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Note: you may need to restart the kernel to use updated packages.\n"
        }
      ],
      "execution_count": 1,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1695220240730
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "from datasets import load_dataset\n",
        "from transformers import (\n",
        "    AutoModelForCausalLM,\n",
        "    AutoTokenizer,\n",
        "    BitsAndBytesConfig,\n",
        "    HfArgumentParser,\n",
        "    TrainingArguments,\n",
        "    pipeline,\n",
        "    logging,\n",
        ")\n",
        "from peft import LoraConfig, PeftModel\n",
        "from trl import SFTTrainer\n",
        "\n",
        "import pandas as pd\n",
        "import ast"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n  from .autonotebook import tqdm as notebook_tqdm\n"
        }
      ],
      "execution_count": 1,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1695220277602
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Creating the directories that will be used during execution\n",
        "\n",
        "**Important note here:** The \"data\" folder will hold the data needed to fine-tune the model. You need to provide this data to the model. In my experiments I generated most of it using the Alpaca method, as described in the repo. The results folder is just there for the model to have somewhere to push its predictions."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "current_dir = os.getcwd()\n",
        "\n",
        "folders = [\"data\", \"results\"]\n",
        "\n",
        "for folder in folders:\n",
        "    folder_path = os.path.join(current_dir, folder)\n",
        "    \n",
        "    if not os.path.exists(folder_path):\n",
        "        os.makedirs(folder_path)"
      ],
      "outputs": [],
      "execution_count": 2,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1695220277717
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset preprocessing and save"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"data/CORRECTED_PROMPTS_FOR_FINE_TUNING.csv\").rename(columns={\"sql_query\": \"prompt\", \"tables\": \"response\"})\n",
        "df['prompt'] = \"##EXTRACTTABLES:\\n\" + df['prompt']\n",
        "\n",
        "train_df = df[[\"prompt\", \"response\"]].sample(frac=0.9, random_state=101)\n",
        "test_df  = df[[\"prompt\", \"response\"]].drop(train_df.index)\n",
        "\n",
        "# Save the dataframes to .jsonl files\n",
        "train_df.to_json('data/train.jsonl', orient='records', lines=True)\n",
        "test_df.to_json('data/test.jsonl', orient='records', lines=True)"
      ],
      "outputs": [],
      "execution_count": 3,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1695217793427
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Visualizing examples:"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.head()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 4,
          "data": {
            "text/plain": "                                                prompt  \\\n37   ##EXTRACTTABLES:\\nWITH cte_enrollment AS (\\n  ...   \n109  ##EXTRACTTABLES:\\nWITH cte1 AS (\\n  SELECT p.p...   \n31   ##EXTRACTTABLES:\\nWITH cte1 AS (\\n  SELECT \\n ...   \n89   ##EXTRACTTABLES:\\nWITH cte1 AS (\\n  SELECT\\n  ...   \n66   ##EXTRACTTABLES:\\nWITH cte1 AS (\\n    SELECT \\...   \n\n                                              response  \n37   ['education.institution.enrollment', 'educatio...  \n109  ['patients', 'appointments', 'doctors', 'presc...  \n31   ['insurance.customers', 'insurance.policies', ...  \n89   ['news.articles', 'news.categories', 'news.com...  \n66   ['customers', 'orders', 'products', 'order_pro...  ",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>prompt</th>\n      <th>response</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>37</th>\n      <td>##EXTRACTTABLES:\\nWITH cte_enrollment AS (\\n  ...</td>\n      <td>['education.institution.enrollment', 'educatio...</td>\n    </tr>\n    <tr>\n      <th>109</th>\n      <td>##EXTRACTTABLES:\\nWITH cte1 AS (\\n  SELECT p.p...</td>\n      <td>['patients', 'appointments', 'doctors', 'presc...</td>\n    </tr>\n    <tr>\n      <th>31</th>\n      <td>##EXTRACTTABLES:\\nWITH cte1 AS (\\n  SELECT \\n ...</td>\n      <td>['insurance.customers', 'insurance.policies', ...</td>\n    </tr>\n    <tr>\n      <th>89</th>\n      <td>##EXTRACTTABLES:\\nWITH cte1 AS (\\n  SELECT\\n  ...</td>\n      <td>['news.articles', 'news.categories', 'news.com...</td>\n    </tr>\n    <tr>\n      <th>66</th>\n      <td>##EXTRACTTABLES:\\nWITH cte1 AS (\\n    SELECT \\...</td>\n      <td>['customers', 'orders', 'products', 'order_pro...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 4,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1695217793547
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "position = 0"
      ],
      "outputs": [],
      "execution_count": 5,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1695217793661
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Prompt at position\n",
        "\n",
        "print(train_df[\"prompt\"].iloc[position])"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "##EXTRACTTABLES:\nWITH cte_enrollment AS (\n  SELECT\n    student_id,\n    COUNT(DISTINCT course_id) AS num_courses\n  FROM\n    education.institution.enrollment\n  GROUP BY\n    student_id\n  HAVING\n    COUNT(DISTINCT course_id) >= 3\n),\ncte_average_grade AS (\n  SELECT\n    student_id,\n    AVG(grade) AS avg_grade\n  FROM\n    education.institution.grades\n  GROUP BY\n    student_id\n),\ncte_top_students AS (\n  SELECT\n    e.student_id,\n    e.num_courses,\n    g.avg_grade\n  FROM\n    cte_enrollment e\n    JOIN cte_average_grade g ON e.student_id = g.student_id\n  WHERE\n    g.avg_grade >= 80\n),\ncte_course_stats AS (\n  SELECT\n    c.course_id,\n    COUNT(DISTINCT e.student_id) AS num_students,\n    SUM(g.grade) AS total_grade\n  FROM\n    education.institution.courses c\n    LEFT JOIN education.institution.enrollment e ON c.course_id = e.course_id\n    LEFT JOIN education.institution.grades g ON e.student_id = g.student_id AND c.course_id = g.course_id\n  GROUP BY\n    c.course_id\n),\ncte_top_courses AS (\n  SELECT\n    cs.course_id,\n    cs.num_students,\n    cs.total_grade\n  FROM\n    cte_course_stats cs\n  WHERE\n    cs.num_students >= 5\n  ORDER BY\n    cs.total_grade DESC\n  LIMIT 3\n)\nSELECT\n  s.student_id,\n  s.first_name,\n  s.last_name,\n  CONCAT(s.first_name, ' ', s.last_name) AS full_name,\n  s.date_of_birth,\n  UPPER(s.gender) AS gender,\n  c.course_id,\n  c.course_name,\n  cs.num_students,\n  cs.total_grade,\n  t.avg_grade\nFROM\n  education.institution.students s\n  JOIN cte_top_students t ON s.student_id = t.student_id\n  JOIN education.institution.enrollment e ON s.student_id = e.student_id\n  JOIN education.institution.courses c ON e.course_id = c.course_id\n  JOIN cte_course_stats cs ON c.course_id = cs.course_id\n  JOIN cte_top_courses tc ON cs.course_id = tc.course_id\nWHERE\n  s.date_of_birth >= DATE_FORMAT('1990-01-01', '%Y-%m-%d')\n  AND s.gender = 'F'\n  AND t.num_courses >= 5\nORDER BY\n  s.last_name ASC,\n  s.first_name ASC,\n  c.course_name ASC;\n"
        }
      ],
      "execution_count": 6,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1695217793782
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Outputs at position\n",
        "\n",
        "my_list = ast.literal_eval(train_df[\"response\"].iloc[position])\n",
        "for table in my_list:\n",
        "  print(table)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "education.institution.enrollment\neducation.institution.grades\neducation.institution.courses\neducation.institution.students\n"
        }
      ],
      "execution_count": 7,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1695217793958
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Hyperparameters for LLAMA 2 model"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set model and training data paths\n",
        "model_name = \"NousResearch/llama-2-7b-chat-hf\"\n",
        "dataset_name = \"data/train.jsonl\"\n",
        "new_model = \"llama-2-7b-sql-parser\"\n",
        "\n",
        "# LoRA Configs\n",
        "lora_r = 64\n",
        "lora_alpha = 16\n",
        "lora_dropout = 0.1\n",
        "use_4bit = True\n",
        "bnb_4bit_compute_dtype = \"float16\"\n",
        "bnb_4bit_quant_type = \"nf4\"\n",
        "use_nested_quant = False\n",
        "\n",
        "# Model hyperparameters\n",
        "output_dir = \"results\"\n",
        "num_train_epochs = 3\n",
        "fp16 = False\n",
        "bf16 = False\n",
        "per_device_train_batch_size = 4\n",
        "per_device_eval_batch_size = 4\n",
        "gradient_accumulation_steps = 1\n",
        "gradient_checkpointing = True\n",
        "max_grad_norm = 0.3\n",
        "learning_rate = 2e-4\n",
        "weight_decay = 0.001\n",
        "optim = \"paged_adamw_32bit\"\n",
        "lr_scheduler_type = \"constant\"\n",
        "max_steps = -1\n",
        "warmup_ratio = 0.03\n",
        "group_by_length = True\n",
        "save_steps = 25\n",
        "logging_steps = 5\n",
        "max_seq_length = None\n",
        "packing = False\n",
        "device_map = {\"\": 0}"
      ],
      "outputs": [],
      "execution_count": 4,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1695220298226
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loading Dataset"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "tokenizer.padding_side = \"right\""
      ],
      "outputs": [],
      "execution_count": 14,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1695217934262
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "system_message = \"You are a SQL code reference table finder. You receive a SQL query and return all references to tables\"\n",
        "\n",
        "# Load datasets\n",
        "train_dataset = load_dataset('json', data_files='data/train.jsonl', split=\"train\")\n",
        "valid_dataset = load_dataset('json', data_files='data/test.jsonl', split=\"train\")\n",
        "\n",
        "# Preprocess datasets\n",
        "train_dataset_mapped = train_dataset.map(lambda examples: {'text': [f'[INST] <<SYS>>\\n{system_message.strip()}\\n<</SYS>>\\n\\n' + prompt + ' [/INST] ' + response for prompt, response in zip(examples['prompt'], examples['response'])]}, batched=True)\n",
        "valid_dataset_mapped = valid_dataset.map(lambda examples: {'text': [f'[INST] <<SYS>>\\n{system_message.strip()}\\n<</SYS>>\\n\\n' + prompt + ' [/INST] ' + response for prompt, response in zip(examples['prompt'], examples['response'])]}, batched=True)"
      ],
      "outputs": [],
      "execution_count": 15,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1695217935480
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Bits and Bytes config"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "compute_dtype = getattr(torch, bnb_4bit_compute_dtype)\n",
        "bnb_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=use_4bit,\n",
        "    bnb_4bit_quant_type=bnb_4bit_quant_type,\n",
        "    bnb_4bit_compute_dtype=compute_dtype,\n",
        "    bnb_4bit_use_double_quant=use_nested_quant,\n",
        ")"
      ],
      "outputs": [],
      "execution_count": 16,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1695217936334
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### HF Model Config"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_name,\n",
        "    quantization_config=bnb_config,\n",
        "    device_map=device_map\n",
        ")\n",
        "model.config.use_cache = False\n",
        "model.config.pretraining_tp = 1"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "Loading checkpoint shards: 100%|██████████| 2/2 [01:54<00:00, 57.19s/it]\n"
        }
      ],
      "execution_count": 17,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1695218052427
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### PEFT Config"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "peft_config = LoraConfig(\n",
        "    lora_alpha=lora_alpha,\n",
        "    lora_dropout=lora_dropout,\n",
        "    r=lora_r,\n",
        "    bias=\"none\",\n",
        "    task_type=\"CAUSAL_LM\",\n",
        ")"
      ],
      "outputs": [],
      "execution_count": 18,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1695218052552
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Setting up Training Arguments"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set training parameters\n",
        "training_arguments = TrainingArguments(\n",
        "    output_dir=output_dir,\n",
        "    num_train_epochs=num_train_epochs,\n",
        "    per_device_train_batch_size=per_device_train_batch_size,\n",
        "    gradient_accumulation_steps=gradient_accumulation_steps,\n",
        "    optim=optim,\n",
        "    save_steps=save_steps,\n",
        "    logging_steps=logging_steps,\n",
        "    learning_rate=learning_rate,\n",
        "    weight_decay=weight_decay,\n",
        "    fp16=fp16,\n",
        "    bf16=bf16,\n",
        "    max_grad_norm=max_grad_norm,\n",
        "    max_steps=max_steps,\n",
        "    warmup_ratio=warmup_ratio,\n",
        "    group_by_length=group_by_length,\n",
        "    lr_scheduler_type=lr_scheduler_type,\n",
        "    report_to=\"all\",\n",
        "    evaluation_strategy=\"steps\",\n",
        "    eval_steps=5  # Evaluate every 20 steps\n",
        ")"
      ],
      "outputs": [],
      "execution_count": 19,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1695218052656
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Creating Trainer Instance"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set supervised fine-tuning parameters\n",
        "trainer = SFTTrainer(\n",
        "    model=model,\n",
        "    train_dataset=train_dataset_mapped,\n",
        "    eval_dataset=valid_dataset_mapped,  # Pass validation dataset here\n",
        "    peft_config=peft_config,\n",
        "    dataset_text_field=\"text\",\n",
        "    max_seq_length=max_seq_length,\n",
        "    tokenizer=tokenizer,\n",
        "    args=training_arguments,\n",
        "    packing=packing,\n",
        ")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/peft/utils/other.py:102: FutureWarning: prepare_model_for_int8_training is deprecated and will be removed in a future version. Use prepare_model_for_kbit_training instead.\n  warnings.warn(\n/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:159: UserWarning: You didn't pass a `max_seq_length` argument to the SFTTrainer, this will default to 1024\n  warnings.warn(\nMap: 100%|██████████| 180/180 [00:00<00:00, 1421.25 examples/s]\nMap: 100%|██████████| 20/20 [00:00<00:00, 1219.93 examples/s]\n"
        }
      ],
      "execution_count": 20,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1695218060657
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training..."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train()\n",
        "trainer.model.save_pretrained(new_model)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "You're using a LlamaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "\n    <div>\n      \n      <progress value='135' max='135' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [135/135 11:31, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>5</td>\n      <td>0.663500</td>\n      <td>0.739448</td>\n    </tr>\n    <tr>\n      <td>10</td>\n      <td>0.865400</td>\n      <td>0.583755</td>\n    </tr>\n    <tr>\n      <td>15</td>\n      <td>0.493700</td>\n      <td>0.503857</td>\n    </tr>\n    <tr>\n      <td>20</td>\n      <td>0.476900</td>\n      <td>0.411998</td>\n    </tr>\n    <tr>\n      <td>25</td>\n      <td>0.341900</td>\n      <td>0.348327</td>\n    </tr>\n    <tr>\n      <td>30</td>\n      <td>0.287200</td>\n      <td>0.304760</td>\n    </tr>\n    <tr>\n      <td>35</td>\n      <td>0.285300</td>\n      <td>0.284120</td>\n    </tr>\n    <tr>\n      <td>40</td>\n      <td>0.250400</td>\n      <td>0.267132</td>\n    </tr>\n    <tr>\n      <td>45</td>\n      <td>0.230900</td>\n      <td>0.253380</td>\n    </tr>\n    <tr>\n      <td>50</td>\n      <td>0.190400</td>\n      <td>0.247205</td>\n    </tr>\n    <tr>\n      <td>55</td>\n      <td>0.204700</td>\n      <td>0.238167</td>\n    </tr>\n    <tr>\n      <td>60</td>\n      <td>0.189600</td>\n      <td>0.236571</td>\n    </tr>\n    <tr>\n      <td>65</td>\n      <td>0.195600</td>\n      <td>0.228514</td>\n    </tr>\n    <tr>\n      <td>70</td>\n      <td>0.162300</td>\n      <td>0.230597</td>\n    </tr>\n    <tr>\n      <td>75</td>\n      <td>0.197600</td>\n      <td>0.226341</td>\n    </tr>\n    <tr>\n      <td>80</td>\n      <td>0.135300</td>\n      <td>0.220645</td>\n    </tr>\n    <tr>\n      <td>85</td>\n      <td>0.184300</td>\n      <td>0.221824</td>\n    </tr>\n    <tr>\n      <td>90</td>\n      <td>0.171900</td>\n      <td>0.216035</td>\n    </tr>\n    <tr>\n      <td>95</td>\n      <td>0.144100</td>\n      <td>0.214369</td>\n    </tr>\n    <tr>\n      <td>100</td>\n      <td>0.146700</td>\n      <td>0.214983</td>\n    </tr>\n    <tr>\n      <td>105</td>\n      <td>0.126200</td>\n      <td>0.220284</td>\n    </tr>\n    <tr>\n      <td>110</td>\n      <td>0.147500</td>\n      <td>0.214134</td>\n    </tr>\n    <tr>\n      <td>115</td>\n      <td>0.131000</td>\n      <td>0.215005</td>\n    </tr>\n    <tr>\n      <td>120</td>\n      <td>0.130400</td>\n      <td>0.217448</td>\n    </tr>\n    <tr>\n      <td>125</td>\n      <td>0.122300</td>\n      <td>0.211751</td>\n    </tr>\n    <tr>\n      <td>130</td>\n      <td>0.169700</td>\n      <td>0.211263</td>\n    </tr>\n    <tr>\n      <td>135</td>\n      <td>0.148100</td>\n      <td>0.205218</td>\n    </tr>\n  </tbody>\n</table><p>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 21,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1695218767046
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Loosely Evaluating"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Test the model\n",
        "logging.set_verbosity(logging.CRITICAL)\n",
        "prompt = f\"[INST] <<SYS>>\\n{system_message}\\n<</SYS>>\\n\\n##EXTRACTTABLES:\\nSELECT * FROM [database].[table1].new_tensors WHERE datatensor_length > 1000 [/INST]\" # replace the command here with something relevant to your task\n",
        "pipe = pipeline(task=\"text-generation\", model=model, tokenizer=tokenizer, max_length=600)\n",
        "result = pipe(prompt)\n",
        "print(result[0]['generated_text'])"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/transformers/generation/utils.py:1270: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use a generation configuration file (see https://huggingface.co/docs/transformers/main_classes/text_generation )\n  warnings.warn(\n"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "[INST] <<SYS>>\nYou are a SQL code reference table finder. You receive a SQL query and return all references to tables\n<</SYS>>\n\n##EXTRACTTABLES:\nSELECT * FROM [database].[table1].new_tensors WHERE datatensor_length > 1000 [/INST] ['database', 'table1', 'new_tensors']\n"
        }
      ],
      "execution_count": 22,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1695218778131
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Inference"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Inference on a known result"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set index to run inference on:\n",
        "index = 0\n",
        "\n",
        "\n",
        "\n",
        "test_text = test_df.iloc[index][\"prompt\"]\n",
        "expected_response = test_df.iloc[index][\"response\"]\n",
        "\n",
        "prompt = f\"[INST] <<SYS>>\\n{system_message}\\n<</SYS>>\\n\\n{test_text} [/INST]\" # replace the command here with something relevant to your task\n",
        "num_new_tokens = 100  # change to the number of new tokens you want to generate\n",
        "\n",
        "# Count the number of tokens in the prompt\n",
        "num_prompt_tokens = len(tokenizer(prompt)['input_ids'])\n",
        "\n",
        "# Calculate the maximum length for the generation\n",
        "max_length = num_prompt_tokens + num_new_tokens\n",
        "\n",
        "gen = pipeline(\n",
        "    'text-generation', \n",
        "    model=model, \n",
        "    tokenizer=tokenizer, \n",
        "    max_length=max_length,\n",
        "    do_sample=True,\n",
        "    temperature=0.2\n",
        ")\n",
        "\n",
        "result = gen(prompt)\n",
        "print(\"PROMPT:\")\n",
        "print(prompt)\n",
        "print(\"\\n\\n\")\n",
        "print(\"RESULT:\")\n",
        "print(result[index]['generated_text'].replace(prompt, ''))\n",
        "\n",
        "print(\"Expected Response:\")\n",
        "for table in ast.literal_eval(expected_response):\n",
        "  print(table)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "PROMPT:\n[INST] <<SYS>>\nYou are a SQL code reference table finder. You receive a SQL query and return all references to tables\n<</SYS>>\n\n##EXTRACTTABLES:\nWITH CustomerDeliveredOrders AS (\n  SELECT \n    CONCAT(c.first_name, ' ', c.last_name) AS customer_name,\n    o.order_id,\n    o.order_date,\n    o.order_status,\n    o.total_price\n  FROM \n    [FreightCoDB].[OrderManagement].shipment_orders o\n  JOIN \n    [FreightCoDB].[ClientRelations].clients c ON o.client_id = c.client_id\n  WHERE \n    o.order_status = 'Delivered'\n),\n\nOrderProducts AS (\n  SELECT \n    p.item_name,\n    p.item_category,\n    p.item_price,\n    oi.order_id,\n    oi.quantity\n  FROM \n    [FreightCoDB].[OrderManagement].order_contents oi\n  JOIN \n    [FreightCoDB].[Inventory].cargo_items p ON oi.item_id = p.item_id\n),\n\nCustomerProductDetails AS (\n  SELECT \n    cdo.customer_name,\n    cdo.order_id,\n    cdo.order_date,\n    cdo.total_price,\n    op.item_name,\n    op.item_category,\n    op.item_price,\n    op.quantity,\n    op.item_price * op.quantity AS total_item_price\n  FROM \n    CustomerDeliveredOrders cdo\n  JOIN \n    OrderProducts op ON cdo.order_id = op.order_id\n),\n\nCategoryTotals AS (\n  SELECT \n    cpd.customer_name,\n    cpd.order_id,\n    cpd.order_date,\n    cpd.total_price,\n    cpd.item_category,\n    SUM(cpd.total_item_price) AS total_category_price\n  FROM \n    CustomerProductDetails cpd\n  GROUP BY \n    cpd.customer_name,\n    cpd.order_id,\n    cpd.order_date,\n    cpd.total_price,\n    cpd.item_category\n),\n\nTopCategoryByCustomer AS (\n  SELECT \n    ct.customer_name,\n    ct.order_id,\n    ct.order_date,\n    ct.total_price,\n    ct.item_category,\n    ct.total_category_price,\n    CASE \n      WHEN ct.total_category_price = MAX(ct.total_category_price) OVER (PARTITION BY ct.customer_name) THEN 'Highest'\n      ELSE 'Not Highest'\n    END AS category_status\n  FROM \n    CategoryTotals ct\n),\n\nFinalData AS (\n  SELECT \n    tcb.customer_name,\n    tcb.order_id,\n    tcb.order_date,\n    tcb.total_price,\n    tcb.item_category,\n    tcb.total_category_price,\n    tcb.category_status,\n    ROW_NUMBER() OVER (PARTITION BY tcb.customer_name ORDER BY tcb.order_date DESC) AS order_rank,\n    COUNT(*) OVER (PARTITION BY tcb.customer_name) AS total_orders,\n    CASE \n      WHEN COUNT(*) OVER (PARTITION BY tcb.customer_name) > 5 THEN 'Loyal Client'\n      ELSE 'Regular Client'\n    END AS client_type\n  FROM \n    TopCategoryByCustomer tcb\n  WHERE \n    ROW_NUMBER() OVER (PARTITION BY tcb.customer_name ORDER BY tcb.order_date DESC) <= 5\n)\n\nSELECT \n  fd.*\nFROM \n  FinalData fd\nCROSS JOIN \n  [FreightCoDB].[EmployeeManagement].staff_members e\nWHERE \n  e.staff_id = 1\nORDER BY \n  fd.order_date DESC; [/INST]\n\n\n\nRESULT:\n ['[FreightCoDB].[OrderManagement].[shipment_orders]', '[FreightCoDB].[ClientRelations].[clients]', '[FreightCoDB].[OrderManagement].[order_contents]', '[FreightCoDB].[Inventory].[cargo_items]', '[FreightCoDB].[OrderManagement].[customer_delivered_orders]', '[FreightCoDB].[OrderManagement].[order_products]', '[FreightCo\nExpected Response:\n[FreightCoDB].[OrderManagement].shipment_orders\n[FreightCoDB].[ClientRelations].clients\n[FreightCoDB].[OrderManagement].order_contents\n[FreightCoDB].[Inventory].cargo_items\n[FreightCoDB].[EmployeeManagement].staff_members\n"
        }
      ],
      "execution_count": 24,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1695218869958
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Inference on a created query:"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"\"\"##EXTRACTTABLES:\n",
        "SELECT repo.CodeText, \n",
        "repo.Lang, \n",
        "MAX(repo.DateEdit) as FinalEdit, \n",
        "repo.Name, \n",
        "repo.Repository, \n",
        "repo.Branch, \n",
        "scr.Length\n",
        "FROM [targetcurves].[repodata].repositories repo\n",
        "LEFT JOIN [targetcurves].[info].scripts scr\n",
        "ON repo.Name = scr.ScriptName\n",
        "WHERE scr.Length < 1000\n",
        "\"\"\"\n",
        "\n",
        "query_base = f\"[INST] <<SYS>>\\n{system_message}\\n<</SYS>>\\n\\n{query} [/INST]\"\n",
        "\n",
        "expected_result = \"\"\"[\"[targetcurves].[repodata].repositories\", \"[targetcurves].[info].scripts\"]\"\"\"\n",
        "\n",
        "result = gen(query)\n",
        "\n",
        "print(result)\n",
        "print(expected_result)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "[{'generated_text': \"##EXTRACTTABLES:\\nSELECT repo.CodeText, \\nrepo.Lang, \\nMAX(repo.DateEdit) as FinalEdit, \\nrepo.Name, \\nrepo.Repository, \\nrepo.Branch, \\nscr.Length\\nFROM [targetcurves].[repodata].repositories repo\\nLEFT JOIN [targetcurves].[info].scripts scr\\nON repo.Name = scr.ScriptName\\nWHERE scr.Length < 1000\\nGROUP BY repo.CodeText, \\nrepo.Lang, \\nrepo.Name, \\nrepo.Repository, \\nrepo.Branch\\nHAVING COUNT(DISTINCT scr.ScriptName) > 1\\nORDER BY repo.Name ASC; [/INST] [INST] <<SYS>>\\nYou are a SQL code reference table finder. You receive a SQL query and return all references to tables\\n<</SYS>>\\n\\nYou receive the following SQL query:\\n\\nSELECT \\n    repo.CodeText, \\n    repo.Lang, \\n    MAX(repo.DateEdit) as FinalEdit, \\n    repo.Name, \\n    repo.Repository, \\n    repo.Branch, \\n    scr.Length\\nFROM \\n    [targetcurves].[repodata].repositories repo\\nLEFT JOIN \\n    [targetcurves].[info].scripts scr\\nON \\n    repo.Name = scr.ScriptName\\nWHERE \\n    scr.Length < 1000\\nGROUP BY \\n    repo.CodeText, \\n    repo.Lang, \\n    repo.Name, \\n    repo.Repository, \\n    repo.Branch\\nHAVING \\n    COUNT(DISTINCT scr.ScriptName) > 1\\nORDER BY \\n    repo.Name ASC; [/INST] ['repodata.repositories', 'info.scripts']\"}]\n[\"[targetcurves].[repodata].repositories\", \"[targetcurves].[info].scripts\"]\n"
        }
      ],
      "execution_count": 25,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1695218972516
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Merging the Model with the LoRA weights:"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_path = f\"{new_model}\"  # change to your preferred path\n",
        "\n",
        "# Reload model in FP16 and merge it with LoRA weights\n",
        "base_model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_name,\n",
        "    low_cpu_mem_usage=True,\n",
        "    return_dict=True,\n",
        "    torch_dtype=torch.float16,\n",
        "    device_map=device_map,\n",
        ")\n",
        "model = PeftModel.from_pretrained(base_model, new_model)\n",
        "model = model.merge_and_unload()\n",
        "\n",
        "# Reload tokenizer to save it\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "tokenizer.padding_side = \"right\"\n",
        "\n",
        "# Save the merged model\n",
        "model.save_pretrained(model_path)\n",
        "tokenizer.save_pretrained(model_path)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "Loading checkpoint shards: 100%|██████████| 2/2 [03:36<00:00, 108.21s/it]\n"
        },
        {
          "output_type": "execute_result",
          "execution_count": 5,
          "data": {
            "text/plain": "('llama-2-7b-sql-parser/tokenizer_config.json',\n 'llama-2-7b-sql-parser/special_tokens_map.json',\n 'llama-2-7b-sql-parser/tokenizer.json')"
          },
          "metadata": {}
        }
      ],
      "execution_count": 5,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1695220716090
        }
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python310-sdkv2",
      "language": "python",
      "display_name": "Python 3.10 - SDK v2"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.11",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "microsoft": {
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      },
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "kernel_info": {
      "name": "python310-sdkv2"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}